2021年度 サブゼミ 第13回 Webスクレイピング
================
Yoshinari Namba
2021/8/11

# 0. イントロダクション

今日のAgendaは以下の3つです．  
1. スクレイピングの概要  
2. Rでの実装  
3. グループワーク

自力でWebからデータを取ってこれるようになることが今日の目標です！

# 1. スクレイピングの概要

## スクレイピングとは?

スクレイピングはWeb上のデータを自動で取得する方法です．  
欲しいデータの量が少ないときはコピペ・ダウンロードすれば良いのですが，膨大なデータが必要な場合は手作業でやると大変です．そこでスクレイピングを使います．

## 必要な知識

Webからデータを取ってくるので，Webサイトを構成するコード(HTML・CSS)をある程度知っておく必要があります.  
- HTML: Webページの枠組みを作る  
- CSS: HTML作った枠組みに肉付け(文字や配色の詳細設定)を行う

今日は深入りしないでおきます．とりあえず，HTMLが「大見出し→小見出し→本文」のような階層構造を持っていることだけ頭に入れておいて下さい！

## 注意点

サーバーを攻撃していると見なされると大変なことになります。データを繰り返し取得する際には適切な時間を空けましょう

## スクレイピングの手順

スクレイピングはざっくり以下の手順で行います(小澤さんのQiita記事)．  
1. 欲しいデータが載っているサイトを探す  
2. 欲しいデータがそのサイトのどの部分に記載されているかを把握する
@ブラウザ  
3. Rでコードを書いてデータを取得する @R

以降はこの手順で実装していきます！

# 2. Rでの実装

## 2-1. 欲しいデータが載っているサイトを探す

PC周辺機器の口コミを分析するケースを考えてみます．口コミはいろんなサイトに載っていると思いますが，ここでは楽天のレビューを使うことにしましょう．

## 2-2. 欲しいデータがそのサイトのどの部分に記載されているかを把握する @ブラウザ

### HTMLコードを開く

次のリンクから楽天のレビューページを開いてください．  
- <https://review.rakuten.co.jp/search/-/100026/cu1001-d0/>

開けたら右クリックをして「検証」を選択してください
(Edgeユーザーは「開発者ツールで調査する」)．

### 欲しいデータがHTML上のどの階層に位置しているのかを確認

左上の矢印マークを押して，欲しいデータが載っている場所をクリックしてください．  
ハイライトされているコードの中に「class =
“…”」という部分が見つかると思います．  
\[おまけ\] Google Chromeの拡張機能Selector Gadgetを使う

## 2-3. Rでコードを書いてデータを取得する @R

コーディングは以下の手順で行います  
- Step1: 準備  
- Step2: 1つページからデータを取得  
- Step3: Step2を利用して2ページ目以降からデータを自動的に取得

### Step1: 準備

RStudioを開いて右上のタブの File -> New Project
から新規プロジェクトを作成しておいてください．

#### パッケージのインストール

スクレイピングには`rvest`というパッケージを使用します．  
あとで使う`tidyverse`も合わせて先に必要なパッケージを呼び出しましょう．

``` r
# パッケージのインストール
install.packages("rvest")

# パッケージの呼び出し
library(rvest)
library(tidyverse)
```

まだインストールしていない人は`install.packages("tidyverse")`から実行するようにしてください．

#### ウェブサイトを指定する

まずはサイトのurlを指定します．htmlを読み込むには`rvest::read_html()`を使います．

``` r
# 対象のサイトのURLを指定
url <- read_html("https://review.rakuten.co.jp/search/-/100026/cu1001-d0/")
```

実行してみるとエラーが出てしまいます．エンコ―ディングの問題で読み込めないみたいです．正しいエンコードを知るには`guess_encoding()`を使います
[1]．

``` r
guess_encoding("https://review.rakuten.co.jp/search/-/100026/cu1001-d0/")
```

    ## # A tibble: 5 x 2
    ##   encoding   confidence
    ##   <chr>           <dbl>
    ## 1 EUC-JP           1   
    ## 2 Big5             0.85
    ## 3 GB18030          0.79
    ## 4 EUC-KR           0.64
    ## 5 ISO-8859-1       0.26

このサイトは`EUC-JP`というエンコードが信憑性が高そうです．このエンコードで再度読み込みます．

``` r
# エンコードを指定して再度読み込み
url <- read_html("https://review.rakuten.co.jp/search/-/100026/cu1001-d0/", 
                 encoding = "EUC-JP")
```

### Step2: 1つのページからデータを取得

urlから欲しいデータを取ってくるには`html_nodes()`というコマンドを使用します．`()`内には先ほどブラウザで確認したパス(HTML上の位置)を指定します．また，取ってきたデータをテキストの形式で出力するために`html_text()`を使います．

``` r
# データの取得
reviews <- url %>% 
  html_nodes(".ratCustomAppearTarget") %>%  # 欲しい情報の位置を指定
  html_text()                               # テキスト形式で出力
```

ちゃんとデータが取れているか最初の10行を確認してみましょう．

``` r
# 確認
head(reviews, n = 10)
```

    ##  [1] "\n購入し約半年でUSB充電ジャックが壊れて使い物になりませんでした。\nまた充電後の無線での使用時間も短いように感じました。\n改良が必要と思います。\n"                                                                                                                                                             
    ##  [2] "\nエレコム normas カメラ用バックパック用に購入しました。小さめなバックパックですがヘビーなカメラなどを入れるとかなり重くなり、肩のショルダー部が肩に食い込んできます。これを装着することで楽に背負う事ができます。\n最初は型が馴染むまで硬いですが徐々に柔らかくなってきます。緩めに背負うと良いと思います。\n"
    ##  [3] "\n全く問題なく使用できました。\nコスパ最高です。\n"                                                                                                                                                                                                                                                            
    ##  [4] "\n白黒印刷で出力速いので期待した通りでした!!\n欲を言えば、二分の一印刷できると紙の節約になるかな\n"                                                                                                                                                                                                            
    ##  [5] "\nすぐ届きました、ありがとうございました。\n"                                                                                                                                                                                                                                                                  
    ##  [6] "\n注文翌日に商品が届きました\n想像より大きく重量感がありましたが、悪くないです\n設定動作問題なく利用しています\nレシーバを収納できないのが残念です\n他社の静音よりはクリック音がします\n"                                                                                                                      
    ##  [7] "\n販売写真と違う。スマートな印象はない。\nしかし軽い。オモチャのような軽さ。\n使えるので不自由はない。\nノートパソコンと持ち歩くので凸凹したスイッチが壊れないように工夫したい。\n"                                                                                                                            
    ##  [8] "\n商品が到着しました！ 安価なので購入、とりあえず使ってみます。ありがとうございました！\n"                                                                                                                                                                                                                     
    ##  [9] "\n迅速に対応していただきお品物がすぐに届きました。\n"                                                                                                                                                                                                                                                          
    ## [10] "\n無線USBが入っていなかったので☆2です。\nこれでは使えません…残念です。\n"

`\n`が何度も出てきて気持ち悪いですね…
ちなみに`\n`は改行を表しています．`str_replace_all()`を使って消してみましょう．

``` r
# \n を削除
reviews <- reviews %>% 
  str_replace_all(pattern = '\n', replacement = '')

# 確認
head(reviews, n = 10)
```

    ##  [1] "購入し約半年でUSB充電ジャックが壊れて使い物になりませんでした。また充電後の無線での使用時間も短いように感じました。改良が必要と思います。"                                                                                                                                                               
    ##  [2] "エレコム normas カメラ用バックパック用に購入しました。小さめなバックパックですがヘビーなカメラなどを入れるとかなり重くなり、肩のショルダー部が肩に食い込んできます。これを装着することで楽に背負う事ができます。最初は型が馴染むまで硬いですが徐々に柔らかくなってきます。緩めに背負うと良いと思います。"
    ##  [3] "全く問題なく使用できました。コスパ最高です。"                                                                                                                                                                                                                                                            
    ##  [4] "白黒印刷で出力速いので期待した通りでした!!欲を言えば、二分の一印刷できると紙の節約になるかな"                                                                                                                                                                                                            
    ##  [5] "すぐ届きました、ありがとうございました。"                                                                                                                                                                                                                                                                
    ##  [6] "注文翌日に商品が届きました想像より大きく重量感がありましたが、悪くないです設定動作問題なく利用していますレシーバを収納できないのが残念です他社の静音よりはクリック音がします"                                                                                                                            
    ##  [7] "販売写真と違う。スマートな印象はない。しかし軽い。オモチャのような軽さ。使えるので不自由はない。ノートパソコンと持ち歩くので凸凹したスイッチが壊れないように工夫したい。"                                                                                                                                
    ##  [8] "商品が到着しました！ 安価なので購入、とりあえず使ってみます。ありがとうございました！"                                                                                                                                                                                                                   
    ##  [9] "迅速に対応していただきお品物がすぐに届きました。"                                                                                                                                                                                                                                                        
    ## [10] "無線USBが入っていなかったので☆2です。これでは使えません…残念です。"

とりあえずこのページから必要なデータが取れましたね．

### Step3: 2ページ目以降からデータを自動的に取得

1ページで終わりならコピペとそれほど労力はかわらないかもしれません．でも，数十，数百ページからデータを取ろうとするとスクレイピングの方が圧倒的に早いです．  
ここからはStep2で書いたコードを使って複数ページからデータを取得するコードを書きます

#### URLの規則を把握する

ページを変えるとURLも変わるため，指定するURLを変えなければいけません．  
URLの変化の仕方が規則的ならば複数ページからデータを取る作業を自動化することができます．  
実際に2ページ目を見てみると末尾が`....-d0-p2/`，3ページ目は`...-d0-p3/`となっています．

``` r
# データを取得
for(i in 2:10){
  url_tmp <- paste0("https://review.rakuten.co.jp/search/-/100026/cu1001-d0-p", i, "/") %>% 
    read_html(encoding = "EUC-JP")
  reviews_tmp <- url_tmp %>% 
    html_nodes(".ratCustomAppearTarget") %>% 
    html_text() %>% 
    str_replace_all(pattern = "\n", replacement = "")
  reviews <- c(reviews, reviews_tmp)
  Sys.sleep(1)
}

# 確認
reviews[501:510]
```

    ##  [1] NA NA NA NA NA NA NA NA NA NA

[1] `guess_encoding`は`tidyverse`の中にある`readr`というパッケージの中にあります．
